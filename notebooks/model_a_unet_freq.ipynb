{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b10b72ae",
   "metadata": {},
   "source": [
    "# Model A: Curriculum Learning - Other/Piano Extraction\n",
    "\n",
    "**Curriculum Learning Strategy:**\n",
    "1. **Stage 1:** Extract \"other\" from simplified mixture (vocals + other only)\n",
    "2. **Stage 2:** Extract \"other\" from full mixture (drums + bass + vocals + other)\n",
    "\n",
    "**MUSDB18 Dataset:** 4 stems per track (drums, bass, other, vocals)\n",
    "\n",
    "**Workflow:**\n",
    "- Load MUSDB18 ‚Üí prepare curriculum batches\n",
    "- Train Stage 1 on simpler 2-source task\n",
    "- Train Stage 2 on full 4-source mixture using Stage 1 weights\n",
    "- Test on uploaded song (10 seconds from 1:00-1:10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c340beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Setup complete | Device: cpu | Project: C:\\Users\\amita\\source\\repos\\Deep learning on computational accelerators\\Final_Project_Deep_Learning\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "# Setup paths\n",
    "project_root = Path(os.getcwd()).resolve()\n",
    "if project_root.name.lower() == \"notebooks\":\n",
    "    project_root = project_root.parent\n",
    "\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "checkpoints_dir = project_root / \"checkpoints\"\n",
    "data_dir = project_root / \"data\"\n",
    "\n",
    "checkpoints_dir.mkdir(exist_ok=True, parents=True)\n",
    "data_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"‚úì Setup complete | Device: {device} | Project: {project_root}\")\n",
    "\n",
    "# Import model components\n",
    "from models.model_a_unet_freq import (\n",
    "    STFTProcessor, FrequencyDomainUNet, \n",
    "    SourceSeparationDataset, ModelATrainer, ModelAInference\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "767ac252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LOADING MUSDB18 DATASET\n",
      "======================================================================\n",
      "‚úì musdb library found\n",
      "\n",
      "Loading MUSDB18 (auto-downloading if needed)...\n",
      "Note: First run may take time. Dataset will be cached for future use.\n",
      "\n",
      "‚úì MUSDB18 loaded successfully!\n",
      "‚úì Available tracks: 144\n"
     ]
    }
   ],
   "source": [
    "# Load MUSDB18 dataset - Auto download if not present\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LOADING MUSDB18 DATASET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    import musdb\n",
    "    print(\"‚úì musdb library found\")\n",
    "except ImportError:\n",
    "    print(\"Installing musdb...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"musdb\", \"-q\"])\n",
    "    import musdb\n",
    "\n",
    "print(\"\\nLoading MUSDB18 (auto-downloading if needed)...\")\n",
    "print(\"Note: First run may take time. Dataset will be cached for future use.\\n\")\n",
    "\n",
    "try:\n",
    "    mus = musdb.DB(download=True)\n",
    "    tracks = mus.tracks\n",
    "    print(f\"‚úì MUSDB18 loaded successfully!\")\n",
    "    print(f\"‚úì Available tracks: {len(tracks)}\")\n",
    "    use_real_musdb = True\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not load MUSDB18: {e}\")\n",
    "    print(\"Will use synthetic data instead\")\n",
    "    mus = None\n",
    "    use_real_musdb = False\n",
    "\n",
    "# MUSDB18 stems: [0]=drums, [1]=bass, [2]=other, [3]=vocals\n",
    "STEM_NAMES = {0: 'drums', 1: 'bass', 2: 'other', 3: 'vocals'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a7a1c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì MUSDB18 already available\n"
     ]
    }
   ],
   "source": [
    "# Manual MUSDB18 Download Instructions\n",
    "if not use_real_musdb:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"MUSDB18 DATASET REQUIRED\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nThe musdb library doesn't support automatic downloads.\")\n",
    "    print(\"Please follow these steps to download MUSDB18:\\n\")\n",
    "    print(\"1. Visit: https://sigsep.github.io/datasets/musdb.html\")\n",
    "    print(\"2. Download the MUSDB18-HQ dataset (~23GB)\")\n",
    "    print(\"3. Extract the ZIP file to:\")\n",
    "    print(f\"   {musdb_root}\")\n",
    "    print(\"\\n4. After extraction, the structure should be:\")\n",
    "    print(f\"   {musdb_root}/\")\n",
    "    print(f\"     ‚îú‚îÄ‚îÄ train/\")\n",
    "    print(f\"     ‚îÇ   ‚îú‚îÄ‚îÄ A Classic Education - NightOwl/\")\n",
    "    print(f\"     ‚îÇ   ‚îú‚îÄ‚îÄ ...\")\n",
    "    print(f\"     ‚îî‚îÄ‚îÄ test/\")\n",
    "    print(f\"         ‚îú‚îÄ‚îÄ ...\")\n",
    "    print(\"\\n5. Then re-run cells 2-3 to detect the dataset\")\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "else:\n",
    "    print(\"‚úì MUSDB18 already available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbb748fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CURRICULUM LEARNING DATA PREPARATION\n",
      "======================================================================\n",
      "‚úì Loading cached curriculum data (skipping MUSDB18 processing)...\n",
      "‚úì Loaded 50 cached samples per stage\n",
      "\n",
      "‚úì Stage 1 (Vocals + Other ‚Üí Other): 50 samples\n",
      "‚úì Stage 2 (Full Mixture ‚Üí Other): 50 samples\n"
     ]
    }
   ],
   "source": [
    "# Prepare curriculum learning data\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CURRICULUM LEARNING DATA PREPARATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def prepare_curriculum_data(num_tracks=50):\n",
    "    \"\"\"Prepare data for curriculum learning using MUSDB18\"\"\"\n",
    "    \n",
    "    if not use_real_musdb or mus is None:\n",
    "        raise ValueError(\n",
    "            \"MUSDB18 dataset could not be loaded.\\n\"\n",
    "            \"Please check your internet connection and try again.\\n\"\n",
    "            \"The musdb library will attempt to download automatically.\"\n",
    "        )\n",
    "    \n",
    "    tracks = mus.tracks[:num_tracks]\n",
    "    print(f\"\\nProcessing {len(tracks)} MUSDB18 tracks for curriculum learning...\")\n",
    "    \n",
    "    stage1_mixture_paths = []\n",
    "    stage1_target_paths = []\n",
    "    stage2_mixture_paths = []\n",
    "    stage2_target_paths = []\n",
    "    \n",
    "    cache_dir = data_dir / \"curriculum_cache\"\n",
    "    cache_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    for idx, track in enumerate(tracks):\n",
    "        try:\n",
    "            # Extract stems\n",
    "            drums = track.targets['drums'].audio\n",
    "            bass = track.targets['bass'].audio\n",
    "            other = track.targets['other'].audio\n",
    "            vocals = track.targets['vocals'].audio\n",
    "            \n",
    "            # Create mixtures\n",
    "            # Stage 1: vocals + other (simplified)\n",
    "            mixture_s1 = vocals + other\n",
    "            # Stage 2: drums + bass + other + vocals (full)\n",
    "            mixture_s2 = drums + bass + other + vocals\n",
    "            \n",
    "            # Resample to 22050 Hz if needed\n",
    "            # Use MUSDB18 default sample rate (44100 Hz)\n",
    "            sr = getattr(track, 'sample_rate', None) or 44100\n",
    "            \n",
    "            if sr != 22050:\n",
    "                from scipy import signal\n",
    "                n_samples = int(len(other) * 22050 / sr)\n",
    "                other = signal.resample(other, n_samples)\n",
    "                mixture_s1 = signal.resample(mixture_s1, n_samples)\n",
    "                mixture_s2 = signal.resample(mixture_s2, n_samples)\n",
    "            \n",
    "            # Convert stereo to mono\n",
    "            if other.ndim > 1:\n",
    "                other = np.mean(other, axis=1)\n",
    "            if mixture_s1.ndim > 1:\n",
    "                mixture_s1 = np.mean(mixture_s1, axis=1)\n",
    "            if mixture_s2.ndim > 1:\n",
    "                mixture_s2 = np.mean(mixture_s2, axis=1)\n",
    "            \n",
    "            # Normalize\n",
    "            other = other / (np.max(np.abs(other)) + 1e-8)\n",
    "            mixture_s1 = mixture_s1 / (np.max(np.abs(mixture_s1)) + 1e-8)\n",
    "            mixture_s2 = mixture_s2 / (np.max(np.abs(mixture_s2)) + 1e-8)\n",
    "            \n",
    "            # Save files\n",
    "            s1_mix_path = cache_dir / f\"stage1_mixture_{idx:03d}.npy\"\n",
    "            s1_tgt_path = cache_dir / f\"stage1_target_{idx:03d}.npy\"\n",
    "            s2_mix_path = cache_dir / f\"stage2_mixture_{idx:03d}.npy\"\n",
    "            s2_tgt_path = cache_dir / f\"stage2_target_{idx:03d}.npy\"\n",
    "            \n",
    "            np.save(s1_mix_path, mixture_s1.astype(np.float32))\n",
    "            np.save(s1_tgt_path, other.astype(np.float32))\n",
    "            np.save(s2_mix_path, mixture_s2.astype(np.float32))\n",
    "            np.save(s2_tgt_path, other.astype(np.float32))\n",
    "            \n",
    "            stage1_mixture_paths.append(str(s1_mix_path))\n",
    "            stage1_target_paths.append(str(s1_tgt_path))\n",
    "            stage2_mixture_paths.append(str(s2_mix_path))\n",
    "            stage2_target_paths.append(str(s2_tgt_path))\n",
    "            \n",
    "            if (idx + 1) % 10 == 0:\n",
    "                print(f\"  Processed {idx + 1}/{len(tracks)} tracks...\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è Skipping track {idx} ({track.name}): {str(e)[:50]}\")\n",
    "            continue\n",
    "    \n",
    "    if not stage1_mixture_paths:\n",
    "        raise ValueError(\"No tracks could be processed from MUSDB18\")\n",
    "    \n",
    "    return (stage1_mixture_paths, stage1_target_paths,\n",
    "            stage2_mixture_paths, stage2_target_paths)\n",
    "\n",
    "# Check if cache already exists\n",
    "cache_dir = data_dir / \"curriculum_cache\"\n",
    "cached_files = sorted(list(cache_dir.glob(\"stage1_mixture_*.npy\"))) if cache_dir.exists() else []\n",
    "\n",
    "if cached_files and len(cached_files) > 0:\n",
    "    print(\"‚úì Loading cached curriculum data (skipping MUSDB18 processing)...\")\n",
    "    s1_mix = sorted([str(p) for p in cache_dir.glob(\"stage1_mixture_*.npy\")])\n",
    "    s1_tgt = sorted([str(p) for p in cache_dir.glob(\"stage1_target_*.npy\")])\n",
    "    s2_mix = sorted([str(p) for p in cache_dir.glob(\"stage2_mixture_*.npy\")])\n",
    "    s2_tgt = sorted([str(p) for p in cache_dir.glob(\"stage2_target_*.npy\")])\n",
    "    print(f\"‚úì Loaded {len(s1_mix)} cached samples per stage\")\n",
    "else:\n",
    "    print(\"‚è≥ No cache found. Processing 50 MUSDB18 tracks (first time only)...\")\n",
    "    s1_mix, s1_tgt, s2_mix, s2_tgt = prepare_curriculum_data(num_tracks=50)\n",
    "\n",
    "print(f\"\\n‚úì Stage 1 (Vocals + Other ‚Üí Other): {len(s1_mix)} samples\")\n",
    "print(f\"‚úì Stage 2 (Full Mixture ‚Üí Other): {len(s2_mix)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ed0efc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CREATING DATALOADERS FOR CURRICULUM LEARNING\n",
      "======================================================================\n",
      "\n",
      "Stage 1: Vocals Extraction\n",
      "  Train: 40 | Val: 10\n",
      "\n",
      "Stage 2: Other/Piano Extraction\n",
      "  Train: 40 | Val: 10\n",
      "\n",
      "‚úì All dataloaders created\n"
     ]
    }
   ],
   "source": [
    "# Create dataloaders for both stages\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CREATING DATALOADERS FOR CURRICULUM LEARNING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "stft_processor = STFTProcessor(n_fft=2048, hop_length=512)\n",
    "\n",
    "# Stage 1: Vocals extraction\n",
    "print(\"\\nStage 1: Vocals Extraction\")\n",
    "stage1_dataset = SourceSeparationDataset(\n",
    "    mixture_paths=s1_mix,\n",
    "    target_paths=s1_tgt,\n",
    "    stft_processor=stft_processor,\n",
    "    normalize=False  # Disable normalization to preserve log->linear consistency\n",
    ")\n",
    "\n",
    "s1_train_size = int(0.8 * len(stage1_dataset))\n",
    "s1_val_size = len(stage1_dataset) - s1_train_size\n",
    "s1_train_data, s1_val_data = random_split(stage1_dataset, [s1_train_size, s1_val_size])\n",
    "\n",
    "s1_train_loader = DataLoader(s1_train_data, batch_size=4, shuffle=True, num_workers=0)\n",
    "s1_val_loader = DataLoader(s1_val_data, batch_size=4, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"  Train: {len(s1_train_data)} | Val: {len(s1_val_data)}\")\n",
    "\n",
    "# Stage 2: Other (piano) extraction\n",
    "print(\"\\nStage 2: Other/Piano Extraction\")\n",
    "stage2_dataset = SourceSeparationDataset(\n",
    "    mixture_paths=s2_mix,\n",
    "    target_paths=s2_tgt,\n",
    "    stft_processor=stft_processor,\n",
    "    normalize=False  # Disable normalization to preserve log->linear consistency\n",
    ")\n",
    "\n",
    "s2_train_size = int(0.8 * len(stage2_dataset))\n",
    "s2_val_size = len(stage2_dataset) - s2_train_size\n",
    "s2_train_data, s2_val_data = random_split(stage2_dataset, [s2_train_size, s2_val_size])\n",
    "\n",
    "s2_train_loader = DataLoader(s2_train_data, batch_size=4, shuffle=True, num_workers=0)\n",
    "s2_val_loader = DataLoader(s2_val_data, batch_size=4, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"  Train: {len(s2_train_data)} | Val: {len(s2_val_data)}\")\n",
    "\n",
    "print(\"\\n‚úì All dataloaders created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "014e4607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODEL INITIALIZATION & CHECKPOINT MANAGEMENT\n",
      "======================================================================\n",
      "\n",
      "‚úì Model created: 7,765,409 parameters\n"
     ]
    }
   ],
   "source": [
    "# Initialize model and trainer\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL INITIALIZATION & CHECKPOINT MANAGEMENT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_config = {\n",
    "    'in_channels': 1,\n",
    "    'base_channels': 32,\n",
    "    'depth': 4,\n",
    "    'use_batch_norm': True\n",
    "}\n",
    "\n",
    "model = FrequencyDomainUNet(**model_config).to(device)\n",
    "print(f\"\\n‚úì Model created: {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "\n",
    "# Checkpoint management\n",
    "def train_stage(stage_num, train_loader, val_loader, num_epochs=20):\n",
    "    \"\"\"Train a curriculum stage with checkpoint management\"\"\"\n",
    "    \n",
    "    checkpoint_path = checkpoints_dir / f\"stage{stage_num}_modelA.pt\"\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"STAGE {stage_num}: CURRICULUM LEARNING\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Check if checkpoint exists\n",
    "    if checkpoint_path.exists():\n",
    "        print(f\"‚úì Checkpoint weights loaded: {checkpoint_path.name}\")\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f\"  Epoch: {checkpoint.get('epoch', '?')} | Val Loss: {checkpoint.get('val_loss', '?'):.6f}\")\n",
    "        # Try to recover history for plotting/printing\n",
    "        train_hist = checkpoint.get('train_loss_history') or checkpoint.get('train_loss')\n",
    "        val_hist = checkpoint.get('val_loss_history') or checkpoint.get('val_loss')\n",
    "        history = None\n",
    "        if isinstance(train_hist, (list, tuple)) and isinstance(val_hist, (list, tuple)) and len(train_hist) == len(val_hist):\n",
    "            history = {\n",
    "                'train_loss': list(train_hist),\n",
    "                'val_loss': list(val_hist)\n",
    "            }\n",
    "            print(\"\\nEpoch losses (train | val) from checkpoint:\")\n",
    "            for epoch_idx, (tr, va) in enumerate(zip(history['train_loss'], history['val_loss']), start=1):\n",
    "                print(f\"  Epoch {epoch_idx:02d}: {tr:.6f} | {va:.6f}\")\n",
    "        return history\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = ModelATrainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        learning_rate=1e-4,\n",
    "        device=device,\n",
    "        use_energy_weighted_loss=False  # Use standard MSE loss\n",
    "    )\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "        trainer.optimizer,\n",
    "        step_size=5,\n",
    "        gamma=0.5\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    print(f\"Starting training... (no checkpoint found)\")\n",
    "    history = trainer.train(num_epochs=num_epochs, save_dir=str(checkpoints_dir))\n",
    "    \n",
    "    # Print per-epoch losses\n",
    "    print(\"\\nEpoch losses (train | val):\")\n",
    "    for epoch_idx, (tr, va) in enumerate(zip(history['train_loss'], history['val_loss']), start=1):\n",
    "        print(f\"  Epoch {epoch_idx:02d}/{num_epochs}: {tr:.6f} | {va:.6f}\")\n",
    "    \n",
    "    # Save checkpoint\n",
    "    best_epoch = np.argmin(history['val_loss']) + 1\n",
    "    torch.save({\n",
    "        'epoch': best_epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'val_loss': float(np.min(history['val_loss'])),\n",
    "        'train_loss': [float(x) for x in history['train_loss']],\n",
    "        'train_loss_history': [float(x) for x in history['train_loss']],\n",
    "        'val_loss_history': [float(x) for x in history['val_loss']]\n",
    "    }, checkpoint_path)\n",
    "    \n",
    "    print(f\"\\n‚úì Checkpoint saved: {checkpoint_path.name}\")\n",
    "    print(f\"  Best epoch: {best_epoch} | Val Loss: {np.min(history['val_loss']):.6f}\")\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec51af8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SANITY CHECK: OVERFITTING ON SMALL DATASET (LR=5e-3 with Grad Clipping)\n",
      "======================================================================\n",
      "\n",
      "‚ö†Ô∏è  Testing overfitting on 1 sample...\n",
      "Previous attempts:\n",
      "  LR=1e-2:  Epoch 1 loss=0.130 ‚Üí Epoch 2 plateaus at 0.228 (stable but slow)\n",
      "  LR=1e-1:  Epoch 1 loss=0.300 ‚Üí Explodes to NaN by epoch 10 (diverges)\n",
      "\n",
      "New strategy: Use intermediate LR (5e-3) with modest gradient clipping (5.0)\n",
      "This prevents divergence while allowing faster convergence than LR=1e-2\n",
      "BatchNorm: disabled | Loss: MSE | Grad clipping: 5.0\n",
      "\n",
      "[Overfitting run: 50 epochs with LR=5e-3 + grad_clip=5.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 0 Diagnostics]\n",
      "  Mix mag range: [0.0000, 4.7291]\n",
      "  Tgt mag range: [0.0000, 4.8964]\n",
      "  Mix lin range: [0.0000, 112.1943]\n",
      "  Tgt lin range: [0.0000, 132.8131]\n",
      "  Target mask range: [0.0000, 1.0000]\n",
      "  Pred mask range: [0.0419, 0.9994]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Grad max (pre-clip): 0.143332\n",
      "  Grad max (post-clip): 0.143332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   2%|‚ñè         | 1/50 [00:03<02:59,  3.66s/it, train_loss=0.149693, val_loss=0.228314]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 01/50: Train Loss 0.149693 | Val Loss 0.228314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   4%|‚ñç         | 2/50 [00:05<02:04,  2.59s/it, train_loss=0.228314, val_loss=0.228318]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 02/50: Train Loss 0.228314 | Val Loss 0.228318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   6%|‚ñå         | 3/50 [00:07<01:45,  2.24s/it, train_loss=0.228318, val_loss=0.228318]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 03/50: Train Loss 0.228318 | Val Loss 0.228318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   8%|‚ñä         | 4/50 [00:09<01:36,  2.11s/it, train_loss=0.228318, val_loss=0.228318]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 04/50: Train Loss 0.228318 | Val Loss 0.228318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  10%|‚ñà         | 5/50 [00:11<01:30,  2.00s/it, train_loss=0.228318, val_loss=0.228318]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 05/50: Train Loss 0.228318 | Val Loss 0.228318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  12%|‚ñà‚ñè        | 6/50 [00:12<01:26,  1.96s/it, train_loss=0.228318, val_loss=0.228318]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 06/50: Train Loss 0.228318 | Val Loss 0.228318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  14%|‚ñà‚ñç        | 7/50 [00:14<01:21,  1.89s/it, train_loss=0.228318, val_loss=0.228318]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 07/50: Train Loss 0.228318 | Val Loss 0.228318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  16%|‚ñà‚ñå        | 8/50 [00:16<01:17,  1.84s/it, train_loss=0.228318, val_loss=0.228318]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 08/50: Train Loss 0.228318 | Val Loss 0.228318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  18%|‚ñà‚ñä        | 9/50 [00:18<01:14,  1.82s/it, train_loss=0.228318, val_loss=0.228318]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 09/50: Train Loss 0.228318 | Val Loss 0.228318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|‚ñà‚ñà        | 10/50 [00:19<01:12,  1.80s/it, train_loss=0.228318, val_loss=0.228318]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10/50: Train Loss 0.228318 | Val Loss 0.228318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|‚ñà‚ñà        | 10/50 [00:21<01:24,  2.12s/it, train_loss=0.228318, val_loss=0.228318]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     36\u001b[39m tiny_trainer = ModelATrainer(\n\u001b[32m     37\u001b[39m     model=tiny_model,\n\u001b[32m     38\u001b[39m     train_loader=tiny_train_loader,\n\u001b[32m   (...)\u001b[39m\u001b[32m     43\u001b[39m     grad_clip_max_norm=\u001b[32m5.0\u001b[39m  \u001b[38;5;66;03m# Prevent gradient explosion\u001b[39;00m\n\u001b[32m     44\u001b[39m )\n\u001b[32m     46\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m[Overfitting run: 50 epochs with LR=5e-3 + grad_clip=5.0]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m tiny_history = \u001b[43mtiny_trainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# Print losses\u001b[39;00m\n\u001b[32m     50\u001b[39m final_train = tiny_history[\u001b[33m'\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\source\\repos\\Deep learning on computational accelerators\\Final_Project_Deep_Learning\\models\\model_a_unet_freq.py:675\u001b[39m, in \u001b[36mModelATrainer.train\u001b[39m\u001b[34m(self, num_epochs, save_dir)\u001b[39m\n\u001b[32m    673\u001b[39m epoch_pbar = tqdm(\u001b[38;5;28mrange\u001b[39m(num_epochs), desc=\u001b[33m'\u001b[39m\u001b[33mEpochs\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    674\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m epoch_pbar:\n\u001b[32m--> \u001b[39m\u001b[32m675\u001b[39m     train_loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    676\u001b[39m     val_loss = \u001b[38;5;28mself\u001b[39m.validate()\n\u001b[32m    678\u001b[39m     \u001b[38;5;28mself\u001b[39m.history[\u001b[33m'\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m'\u001b[39m].append(train_loss)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\source\\repos\\Deep learning on computational accelerators\\Final_Project_Deep_Learning\\models\\model_a_unet_freq.py:589\u001b[39m, in \u001b[36mModelATrainer.train_epoch\u001b[39m\u001b[34m(self, epoch)\u001b[39m\n\u001b[32m    586\u001b[39m     loss = \u001b[38;5;28mself\u001b[39m.loss_fn(predicted_mask, target_mask)\n\u001b[32m    588\u001b[39m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;66;03m# Log gradient magnitude on first batch of first epoch\u001b[39;00m\n\u001b[32m    592\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_first_epoch \u001b[38;5;129;01mand\u001b[39;00m batch_idx == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amita\\anaconda3\\envs\\final-dl-env\\Lib\\site-packages\\torch\\_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amita\\anaconda3\\envs\\final-dl-env\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amita\\anaconda3\\envs\\final-dl-env\\Lib\\site-packages\\torch\\autograd\\graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SANITY CHECK: Overfit on Small Dataset\n",
    "# =============================================================================\n",
    "# This cell tests if the model can memorize a tiny dataset (1-2 samples)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SANITY CHECK: OVERFITTING ON SMALL DATASET (LR=5e-3 with Grad Clipping)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create tiny dataset (just 1 sample)\n",
    "tiny_train_data = torch.utils.data.Subset(stage1_dataset, [0])\n",
    "tiny_val_data = torch.utils.data.Subset(stage1_dataset, [0])\n",
    "\n",
    "tiny_train_loader = DataLoader(tiny_train_data, batch_size=1, shuffle=False)\n",
    "tiny_val_loader = DataLoader(tiny_val_data, batch_size=1, shuffle=False)\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  Testing overfitting on 1 sample...\")\n",
    "print(\"Previous attempts:\")\n",
    "print(\"  LR=1e-2:  Epoch 1 loss=0.130 ‚Üí Epoch 2 plateaus at 0.228 (stable but slow)\")\n",
    "print(\"  LR=1e-1:  Epoch 1 loss=0.300 ‚Üí Explodes to NaN by epoch 10 (diverges)\")\n",
    "print(\"\\nNew strategy: Use intermediate LR (5e-3) with modest gradient clipping (5.0)\")\n",
    "print(\"This prevents divergence while allowing faster convergence than LR=1e-2\")\n",
    "print(\"BatchNorm: disabled | Loss: MSE | Grad clipping: 5.0\")\n",
    "\n",
    "# Instantiate model\n",
    "tiny_model_config = {\n",
    "    'in_channels': 1,\n",
    "    'base_channels': 32,\n",
    "    'depth': 4,\n",
    "    'use_batch_norm': False\n",
    "}\n",
    "\n",
    "tiny_model = FrequencyDomainUNet(**tiny_model_config).to(device)\n",
    "\n",
    "# Train with INTERMEDIATE learning rate + gradient clipping\n",
    "tiny_trainer = ModelATrainer(\n",
    "    model=tiny_model,\n",
    "    train_loader=tiny_train_loader,\n",
    "    val_loader=tiny_val_loader,\n",
    "    learning_rate=5e-3,  # Between 1e-2 (stable) and 1e-1 (diverges)\n",
    "    device=device,\n",
    "    use_energy_weighted_loss=False,\n",
    "    grad_clip_max_norm=5.0  # Prevent gradient explosion\n",
    ")\n",
    "\n",
    "print(\"\\n[Overfitting run: 50 epochs with LR=5e-3 + grad_clip=5.0]\")\n",
    "tiny_history = tiny_trainer.train(num_epochs=50, save_dir=None)\n",
    "\n",
    "# Print losses\n",
    "final_train = tiny_history['train_loss'][-1]\n",
    "final_val = tiny_history['val_loss'][-1]\n",
    "\n",
    "print(f\"\\nFirst 5 epochs:\")\n",
    "for i in range(min(5, len(tiny_history['train_loss']))):\n",
    "    print(f\"  Epoch {i+1}: Train {tiny_history['train_loss'][i]:.6f} | Val {tiny_history['val_loss'][i]:.6f}\")\n",
    "\n",
    "print(f\"\\nEpochs 10, 20, 30, 40, 50:\")\n",
    "for ep in [9, 19, 29, 39, 49]:\n",
    "    if ep < len(tiny_history['train_loss']):\n",
    "        print(f\"  Epoch {ep+1:2d}: Train {tiny_history['train_loss'][ep]:.6f} | Val {tiny_history['val_loss'][ep]:.6f}\")\n",
    "\n",
    "print(f\"\\nFinal loss (epoch 50):\")\n",
    "print(f\"  Train: {final_train:.6f}\")\n",
    "print(f\"  Val:   {final_val:.6f}\")\n",
    "\n",
    "# Plot with enhanced diagnostics\n",
    "fig = plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Linear scale\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "ax1.plot(tiny_history['train_loss'], marker='o', markersize=3, label='Train', alpha=0.7)\n",
    "ax1.plot(tiny_history['val_loss'], marker='s', markersize=3, label='Val', alpha=0.7)\n",
    "ax1.set_title('Loss vs Epoch (Linear scale)', fontsize=11, fontweight='bold')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('MSE Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.axhline(y=1e-4, color='g', linestyle='--', alpha=0.5, label='Excellent (<1e-4)')\n",
    "ax1.axhline(y=1e-2, color='b', linestyle='--', alpha=0.5, label='Good (<1e-2)')\n",
    "ax1.axhline(y=0.1, color='orange', linestyle='--', alpha=0.5, label='Fair (<0.1)')\n",
    "\n",
    "# Log scale\n",
    "ax2 = plt.subplot(1, 3, 2)\n",
    "ax2.semilogy(tiny_history['train_loss'], marker='o', markersize=3, label='Train', alpha=0.7)\n",
    "ax2.semilogy(tiny_history['val_loss'], marker='s', markersize=3, label='Val', alpha=0.7)\n",
    "ax2.set_title('Loss vs Epoch (Log scale)', fontsize=11, fontweight='bold')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('MSE Loss (log)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3, which='both')\n",
    "\n",
    "# Convergence speed (last 20 epochs)\n",
    "ax3 = plt.subplot(1, 3, 3)\n",
    "if len(tiny_history['train_loss']) > 20:\n",
    "    ax3.plot(range(30, 50), tiny_history['train_loss'][30:50], marker='o', markersize=4, label='Train (last 20)', color='C0')\n",
    "    ax3.plot(range(30, 50), tiny_history['val_loss'][30:50], marker='s', markersize=4, label='Val (last 20)', color='C1')\n",
    "    ax3.set_title('Convergence (Epochs 30-50)', fontsize=11, fontweight='bold')\n",
    "else:\n",
    "    ax3.plot(tiny_history['train_loss'], marker='o', markersize=3, label='Train', alpha=0.7)\n",
    "    ax3.plot(tiny_history['val_loss'], marker='s', markersize=3, label='Val', alpha=0.7)\n",
    "    ax3.set_title('Full Training Curve', fontsize=11, fontweight='bold')\n",
    "ax3.set_xlabel('Epoch')\n",
    "ax3.set_ylabel('MSE Loss')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "if final_train < 1e-4:\n",
    "    print(\"‚úÖ EXCELLENT: Model memorized (<1e-4). Ready for Stage 1/2 training.\")\n",
    "elif final_train < 1e-2:\n",
    "    print(\"‚úÖ GOOD: Model learning (<1e-2). Proceed to Stage 1/2 training.\")\n",
    "elif final_train < 0.1:\n",
    "    print(\"‚ö†Ô∏è  FAIR: Model improving but slow (<0.1). May still be usable.\")\n",
    "else:\n",
    "    print(\"‚ùå FAILED: Loss > 0.1. Training pipeline has fundamental issue.\")\n",
    "    print(\"\\nDiagnosis needed:\")\n",
    "    print(\"- Check if mask computation (target_mask = expm1(tgt)/expm1(mix)) is numerically stable\")\n",
    "    print(\"- Verify loss landscape doesn't have sharp discontinuities\")\n",
    "    print(\"- Consider alternative mask formulation or loss function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eca633e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1_history = train_stage(\n",
    "    stage_num=1,\n",
    "    train_loader=s1_train_loader,\n",
    "    val_loader=s1_val_loader,\n",
    "    num_epochs=20\n",
    ")\n",
    "\n",
    "# Plot Stage 1 loss curves\n",
    "if stage1_history is not None:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(stage1_history['train_loss'], label='Train Loss')\n",
    "    plt.plot(stage1_history['val_loss'], label='Val Loss')\n",
    "    plt.title('Stage 1 Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('L1 Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e64027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Stage 1 Performance\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STAGE 1 EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load Stage 1 checkpoint\n",
    "stage1_checkpoint = checkpoints_dir / 'stage1_modelA.pt'\n",
    "if stage1_checkpoint.exists():\n",
    "    checkpoint = torch.load(stage1_checkpoint, map_location=device, weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"\\n‚úì Loaded Stage 1 checkpoint\")\n",
    "    print(f\"  Training epoch: {checkpoint['epoch']}\")\n",
    "    print(f\"  Validation loss: {checkpoint['val_loss']:.6f}\")\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    val_loss_total = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    print(\"\\nEvaluating on validation set...\")\n",
    "    with torch.no_grad():\n",
    "        for batch_data in s1_val_loader:\n",
    "            # Extract mixture magnitude and target magnitude from batch\n",
    "            mixture = batch_data['mixture_mag'].to(device)\n",
    "            target = batch_data['target_mag'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(mixture)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss_fn = torch.nn.L1Loss()\n",
    "            loss = loss_fn(output, target)\n",
    "            val_loss_total += loss.item()\n",
    "            num_batches += 1\n",
    "    \n",
    "    avg_val_loss = val_loss_total / num_batches\n",
    "    print(f\"\\n‚úì Average validation loss: {avg_val_loss:.6f}\")\n",
    "    \n",
    "    # Test on a sample\n",
    "    print(\"\\nTesting on sample audio...\")\n",
    "    test_idx = 0\n",
    "    test_mix = np.load(s1_mix[test_idx])\n",
    "    test_tgt = np.load(s1_tgt[test_idx])\n",
    "    \n",
    "    # Create inference engine\n",
    "    inference_engine = ModelAInference(\n",
    "        model=model,\n",
    "        stft_processor=stft_processor,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # Separate\n",
    "    separated = inference_engine.separate(test_mix)\n",
    "    \n",
    "    # Compute metrics\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "    mse = mean_squared_error(test_tgt, separated)\n",
    "    mae = mean_absolute_error(test_tgt, separated)\n",
    "    \n",
    "    print(f\"  MSE: {mse:.6f}\")\n",
    "    print(f\"  MAE: {mae:.6f}\")\n",
    "    \n",
    "    # Audio playback\n",
    "    print(\"\\nüìä Listen to Stage 1 results:\")\n",
    "    sr = 22050\n",
    "    \n",
    "    def norm_audio(x):\n",
    "        return x / (np.max(np.abs(x)) + 1e-8) * 0.95\n",
    "    \n",
    "    print(\"\\n1. Input (Vocals + Other):\")\n",
    "    display(Audio(norm_audio(test_mix), rate=sr))\n",
    "    \n",
    "    print(\"\\n2. Target (Other/Piano):\")\n",
    "    display(Audio(norm_audio(test_tgt), rate=sr))\n",
    "    \n",
    "    print(\"\\n3. Separated (Stage 1 Output):\")\n",
    "    display(Audio(norm_audio(separated), rate=sr))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Stage 1 evaluation complete. Ready for Stage 2 training.\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Stage 1 checkpoint not found. Please run Stage 1 training first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b56a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_history = train_stage(\n",
    "    stage_num=2,\n",
    "    train_loader=s2_train_loader,\n",
    "    val_loader=s2_val_loader,\n",
    "    num_epochs=20\n",
    ")\n",
    "\n",
    "# Plot Stage 2 loss curves\n",
    "if stage2_history is not None:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(stage2_history['train_loss'], label='Train Loss')\n",
    "    plt.plot(stage2_history['val_loss'], label='Val Loss')\n",
    "    plt.title('Stage 2 Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('L1 Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceff7c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model (Stage 2)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LOADING TRAINED MODEL FOR INFERENCE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "best_checkpoint = checkpoints_dir / 'stage2_modelA.pt'\n",
    "if best_checkpoint.exists():\n",
    "    checkpoint = torch.load(best_checkpoint, map_location=device, weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"\\n‚úì Loaded: {best_checkpoint.name}\")\n",
    "    print(f\"  Best epoch: {checkpoint['epoch']} | Val Loss: {checkpoint['val_loss']:.6f}\")\n",
    "else:\n",
    "    print(\"‚úì Using current model (no checkpoint)\")\n",
    "\n",
    "inference_engine = ModelAInference(\n",
    "    model=model,\n",
    "    stft_processor=stft_processor,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"‚úì Inference engine ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f3969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "from IPython.display import Audio, display\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "# Clear matplotlib cache BEFORE importing\n",
    "import os\n",
    "import shutil\n",
    "cache_dir = os.path.expanduser('~/.matplotlib')\n",
    "if os.path.exists(cache_dir):\n",
    "    try:\n",
    "        shutil.rmtree(cache_dir)\n",
    "        print(\"‚úì Cleared matplotlib cache\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# NOW import matplotlib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Force matplotlib to rebuild font cache\n",
    "try:\n",
    "    matplotlib.font_manager._rebuild()\n",
    "    print(\"‚úì Rebuilt font cache\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Use simple, safe backend and minimal text\n",
    "matplotlib.use('agg')\n",
    "matplotlib.rcParams.update({\n",
    "    'font.size': 9,\n",
    "    'font.family': 'sans-serif',\n",
    "    'figure.dpi': 80,\n",
    "    'savefig.dpi': 80,\n",
    "    'text.usetex': False,\n",
    "    'axes.unicode_minus': False\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TESTING ON UPLOADED SONG & DATABASE SAMPLES WITH STFT VISUALIZATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def visualize_stft_masking(mixture, separated, stft_processor, sr, title_prefix=\"\"):\n",
    "    \"\"\"Visualize STFT magnitude before and after masking with titles\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Compute STFT\n",
    "        mix_mag, mix_phase = stft_processor.waveform_to_magnitude_phase(mixture)\n",
    "        sep_mag, sep_phase = stft_processor.waveform_to_magnitude_phase(separated)\n",
    "        \n",
    "        # Create simple figure WITH titles\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 4), dpi=80)\n",
    "        \n",
    "        # 1. Mixture\n",
    "        mix_db = 20 * np.log10(mix_mag + 1e-8)\n",
    "        im1 = axes[0].imshow(mix_db, aspect='auto', origin='lower', cmap='viridis')\n",
    "        axes[0].set_title(f'{title_prefix}Mixture', fontsize=10, pad=5)\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # 2. Separated\n",
    "        sep_db = 20 * np.log10(sep_mag + 1e-8)\n",
    "        im2 = axes[1].imshow(sep_db, aspect='auto', origin='lower', cmap='viridis')\n",
    "        axes[1].set_title(f'{title_prefix}Separated', fontsize=10, pad=5)\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        # 3. Mask (purple-orange plasma)\n",
    "        mask = sep_mag / (mix_mag + 1e-8)\n",
    "        mask = np.clip(mask, 0, 1)\n",
    "        im3 = axes[2].imshow(mask, aspect='auto', origin='lower', cmap='plasma', vmin=0, vmax=1)\n",
    "        axes[2].set_title(f'{title_prefix}Mask', fontsize=10, pad=5)\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "        plt.subplots_adjust(left=0.02, right=0.98, top=0.88, bottom=0.02, wspace=0.05)\n",
    "        \n",
    "        # Display directly\n",
    "        from IPython.display import display as ipy_display\n",
    "        ipy_display(fig)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        print(f\"‚úì Spectrograms: Mixture (blue-green) | Separated (blue-green) | Mask (purple-orange)\")\n",
    "        \n",
    "        return mix_mag, sep_mag, mask\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Visualization failed: {e}\")\n",
    "        plt.close('all')\n",
    "        return None, None, None\n",
    "\n",
    "def norm_audio(x):\n",
    "    \"\"\"Normalize audio for playback\"\"\"\n",
    "    return x / (np.max(np.abs(x)) + 1e-8) * 0.95\n",
    "\n",
    "def process_long_audio(audio_path, inference_engine, max_chunk_duration=30, sr=22050):\n",
    "    \"\"\"Process long audio files in chunks to avoid memory issues\"\"\"\n",
    "    print(f\"\\n‚ö†Ô∏è Long audio detected. Processing in chunks ({max_chunk_duration}s each)...\")\n",
    "    \n",
    "    duration = librosa.get_duration(filename=str(audio_path))\n",
    "    print(f\"Total duration: {duration:.1f}s\")\n",
    "    \n",
    "    separated_chunks = []\n",
    "    num_chunks = int(np.ceil(duration / max_chunk_duration))\n",
    "    \n",
    "    for chunk_idx in range(num_chunks):\n",
    "        offset = chunk_idx * max_chunk_duration\n",
    "        y_chunk, _ = librosa.load(str(audio_path), sr=sr, mono=True, offset=offset, duration=max_chunk_duration)\n",
    "        y_chunk = y_chunk / (np.max(np.abs(y_chunk)) + 1e-8)\n",
    "        \n",
    "        print(f\"  Processing chunk {chunk_idx + 1}/{num_chunks} ({offset:.0f}s - {offset + max_chunk_duration:.0f}s)...\")\n",
    "        separated_chunk = inference_engine.separate(y_chunk)\n",
    "        separated_chunks.append(separated_chunk)\n",
    "        \n",
    "        del y_chunk\n",
    "        gc.collect()\n",
    "    \n",
    "    separated = np.concatenate(separated_chunks)\n",
    "    print(\"‚úì Chunked processing complete\")\n",
    "    return separated\n",
    "\n",
    "# ============================================================================\n",
    "# Test 1: Uploaded Song\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"TEST 1: UPLOADED SONG\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "audio_files = []\n",
    "search_dirs = [project_root / \"data\", project_root, Path(\".\")]\n",
    "for search_dir in search_dirs:\n",
    "    if search_dir.exists():\n",
    "        for ext in ['*.mp3', '*.wav', '*.flac', '*.m4a', '*.ogg']:\n",
    "            audio_files.extend(glob.glob(str(search_dir / '**' / ext), recursive=True))\n",
    "\n",
    "if audio_files:\n",
    "    test_audio_path = audio_files[0]\n",
    "    print(f\"\\n‚úì Found audio: {Path(test_audio_path).name}\")\n",
    "    \n",
    "    file_size_mb = Path(test_audio_path).stat().st_size / (1024 * 1024)\n",
    "    duration = librosa.get_duration(filename=str(test_audio_path))\n",
    "    print(f\"File size: {file_size_mb:.1f}MB | Duration: {duration:.1f}s\")\n",
    "    \n",
    "    if file_size_mb > 30 or duration > 120:\n",
    "        print(\"‚Üí Using chunked processing (memory-efficient)\")\n",
    "        separated = process_long_audio(test_audio_path, inference_engine, max_chunk_duration=30, sr=22050)\n",
    "        y, sr = librosa.load(test_audio_path, sr=22050, mono=True, duration=30)\n",
    "        test_segment = y\n",
    "    else:\n",
    "        y, sr = librosa.load(test_audio_path, sr=22050, mono=True)\n",
    "        test_segment = y\n",
    "        print(\"‚Üí Processing full audio\")\n",
    "        test_segment = test_segment / (np.max(np.abs(test_segment)) + 1e-8)\n",
    "        \n",
    "        print(\"\\nRunning source separation...\")\n",
    "        separated = inference_engine.separate(test_segment)\n",
    "    \n",
    "    duration_sec = len(test_segment) / sr\n",
    "    print(f\"‚úì Processing song ({duration_sec:.1f}s)\")\n",
    "    \n",
    "    mix_norm = norm_audio(test_segment)\n",
    "    sep_norm = norm_audio(separated[:len(test_segment)])\n",
    "    \n",
    "    print(\"\\nüìä STFT Visualization - Uploaded Song (First 30s):\")\n",
    "    visualize_stft_masking(test_segment, separated[:len(test_segment)], stft_processor, sr, \"Song - \")\n",
    "    \n",
    "    print(\"\\nüìä ORIGINAL MIXTURE (First 30s):\")\n",
    "    display(Audio(mix_norm, rate=sr))\n",
    "    \n",
    "    print(\"\\n‚ú® SEPARATED SOURCE (First 30s):\")\n",
    "    display(Audio(sep_norm, rate=sr))\n",
    "    \n",
    "    del y, test_segment, separated\n",
    "    gc.collect()\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No audio files found in data/ or current directory\")\n",
    "\n",
    "# ============================================================================\n",
    "# Test 2: Database Sample (from curriculum cache)\n",
    "# ============================================================================\n",
    "print(\"\\n\\n\" + \"-\"*70)\n",
    "print(\"TEST 2: DATABASE SAMPLE (FROM CURRICULUM CACHE)\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "if 's2_mix' in locals() and s2_mix and s2_tgt:\n",
    "    sample_idx = np.random.randint(0, min(10, len(s2_mix)))\n",
    "    \n",
    "    db_mixture_path = s2_mix[sample_idx]\n",
    "    db_target_path = s2_tgt[sample_idx]\n",
    "    \n",
    "    print(f\"\\n‚úì Selected sample: {Path(db_mixture_path).name}\")\n",
    "    \n",
    "    db_mixture = np.load(db_mixture_path).astype(np.float32)\n",
    "    db_target = np.load(db_target_path).astype(np.float32)\n",
    "    \n",
    "    print(f\"‚úì Sample duration: {len(db_mixture) / 22050:.2f}s\")\n",
    "    \n",
    "    db_mixture = db_mixture / (np.max(np.abs(db_mixture)) + 1e-8)\n",
    "    db_target = db_target / (np.max(np.abs(db_target)) + 1e-8)\n",
    "    \n",
    "    print(\"\\nRunning source separation...\")\n",
    "    db_separated = inference_engine.separate(db_mixture)\n",
    "    \n",
    "    mix_norm_db = norm_audio(db_mixture)\n",
    "    tgt_norm_db = norm_audio(db_target)\n",
    "    sep_norm_db = norm_audio(db_separated)\n",
    "    \n",
    "    print(\"\\nüìä STFT Visualization - Database Sample:\")\n",
    "    visualize_stft_masking(db_mixture, db_separated, stft_processor, sr=22050, title_prefix=\"DB - \")\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "    db_mse = mean_squared_error(db_target, db_separated)\n",
    "    db_mae = mean_absolute_error(db_target, db_separated)\n",
    "    \n",
    "    print(f\"\\nüìà Performance Metrics:\")\n",
    "    print(f\"  MSE: {db_mse:.6f}\")\n",
    "    print(f\"  MAE: {db_mae:.6f}\")\n",
    "    \n",
    "    print(\"\\nüìä INPUT MIXTURE (Full 4-source):\")\n",
    "    display(Audio(mix_norm_db, rate=22050))\n",
    "    \n",
    "    print(\"\\n‚úì GROUND TRUTH TARGET (Other/Piano):\")\n",
    "    display(Audio(tgt_norm_db, rate=22050))\n",
    "    \n",
    "    print(\"\\n‚ú® MODEL OUTPUT (Separated):\")\n",
    "    display(Audio(sep_norm_db, rate=22050))\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No database samples available. Please run curriculum data preparation first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final-dl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
