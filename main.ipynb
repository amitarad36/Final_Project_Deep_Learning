{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15beab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Verify and install dependencies ---\n",
    "print(\"Verifying and installing missing packages if necessary...\")\n",
    "\n",
    "packages_to_check = [\n",
    "    'numpy', 'matplotlib', 'librosa', 'tqdm', 'sklearn', 'stempeg', 'torch', 'torchvision', 'torchaudio', 'musdb', 'nbformat', 'nbconvert'\n",
    "]\n",
    "\n",
    "for package in packages_to_check:\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"  ✅ {package} is installed.\")\n",
    "    except ImportError:\n",
    "        print(f\"  ❌ {package} is NOT installed. Attempting to install...\")\n",
    "        try:\n",
    "            import sys\n",
    "            import subprocess\n",
    "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
    "            __import__(package)\n",
    "            print(f\"  ✅ {package} is now installed.\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ Failed to install {package}: {e}\")\n",
    "\n",
    "# Special check for PyTorch CUDA\n",
    "print(\"\\n--- PyTorch CUDA status ---\")\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"  ✅ PyTorch with CUDA (version {torch.version.cuda}) is available.\")\n",
    "        print(f\"     CUDA Device Name: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        print(\"  ⚠️ PyTorch is installed, but CUDA is NOT available.\")\n",
    "except ImportError:\n",
    "    print(\"  ❌ PyTorch is not installed.\")\n",
    "\n",
    "print(\"Verification complete.\")\n",
    "\n",
    "# --- 2. Set experiment configs for model_A.ipynb ---\n",
    "MODEL_CONFIG = {\n",
    "    'in_channels': 1,\n",
    "    'out_channels': 1,\n",
    "    'base_filters': 64,\n",
    "    'num_layers': 4,\n",
    "    'batchnorm': True,\n",
    "    'dropout': 0.1,\n",
    "}\n",
    "TRAIN_CONFIG = {\n",
    "    'num_epochs': 50,\n",
    "    'learning_rate': 1e-4,\n",
    "    'patience': 10000,\n",
    "    'batch_size': 2,\n",
    "}\n",
    "OVERFIT_CONFIG = {\n",
    "    'base_filters': 128,\n",
    "    'num_layers': 4,\n",
    "    'batchnorm': True,\n",
    "    'dropout': 0.0,\n",
    "    'learning_rate': 3e-4,\n",
    "    'num_epochs': 100,\n",
    "    'batch_size': 2,\n",
    "    'patience': 10000,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73428ffe",
   "metadata": {},
   "source": [
    "# Main Experiment Controller\n",
    "\n",
    "This notebook lets you control model architecture and training hyperparameters for model_A.ipynb from a single place.\n",
    "\n",
    "**Workflow:**\n",
    "1. Set your experiment configs below (MODEL_CONFIG, TRAIN_CONFIG, OVERFIT_CONFIG).\n",
    "2. Run all cells to verify dependencies and execute model_A.ipynb with your chosen parameters.\n",
    "3. To try different experiments, just change the config values and re-run.\n",
    "\n",
    "**Example:**\n",
    "- Change `base_filters` or `batch_size` in the config dicts to test different model sizes or memory usage.\n",
    "- All results, checkpoints, and logs will be produced as usual by model_A.ipynb.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc61f4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nbformat\n",
    "from nbconvert.preprocessors import ExecutePreprocessor\n",
    "\n",
    "# --- 3. Find and run model_A.ipynb with injected configs ---\n",
    "\n",
    "def find_notebook(filename, search_path=\".\"):\n",
    "    for root, dirs, files in os.walk(search_path):\n",
    "        if filename in files:\n",
    "            return os.path.join(root, filename)\n",
    "    return None\n",
    "\n",
    "notebook_path = find_notebook(\"model_A.ipynb\", \".\")\n",
    "if notebook_path is None:\n",
    "    raise FileNotFoundError(\"model_A.ipynb not found anywhere in the workspace.\")\n",
    "\n",
    "with open(notebook_path) as f:\n",
    "    nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "# Remove autoreload magic commands from the notebook before execution\n",
    "for cell in nb.cells:\n",
    "    if cell.cell_type == 'code':\n",
    "        lines = cell.source.splitlines()\n",
    "        new_lines = [line for line in lines if not line.strip().startswith(('%load_ext autoreload', '%autoreload'))]\n",
    "        cell.source = '\\n'.join(new_lines)\n",
    "\n",
    "# Inject config variables into the first code cell\n",
    "inject_code = [\n",
    "    \"MODEL_CONFIG = globals().get('MODEL_CONFIG', MODEL_CONFIG)\",\n",
    "    \"TRAIN_CONFIG = globals().get('TRAIN_CONFIG', TRAIN_CONFIG)\",\n",
    "    \"OVERFIT_CONFIG = globals().get('OVERFIT_CONFIG', OVERFIT_CONFIG)\"\n",
    "]\n",
    "for cell in nb.cells:\n",
    "    if cell.cell_type == 'code':\n",
    "        cell.source = '\\n'.join(inject_code) + '\\n' + cell.source\n",
    "        break\n",
    "\n",
    "# Execute the notebook\n",
    "ep = ExecutePreprocessor(timeout=1200, kernel_name='python3')\n",
    "try:\n",
    "    ep.preprocess(nb, {'metadata': {'path': os.path.dirname(notebook_path)}})\n",
    "    print(f'model_A.ipynb executed successfully from: {notebook_path}')\n",
    "except Exception as e:\n",
    "    print(f'Error executing model_A.ipynb: {e}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
